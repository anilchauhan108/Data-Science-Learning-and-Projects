{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f97e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy doesn't have support for stemming, \n",
    "# NLTK supports both stemming and lemmatization\n",
    "\n",
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ab3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer   # we have one more stemmer which is snowballstemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6857216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat\n",
      "eats  |  eat\n",
      "eat  |  eat\n",
      "ate  |  ate\n",
      "adjustable  |  adjust\n",
      "rafting  |  raft\n",
      "ability  |  abil\n",
      "meeting  |  meet\n"
     ]
    }
   ],
   "source": [
    "words = ['eating','eats','eat','ate','adjustable','rafting','ability','meeting']\n",
    "\n",
    "for word in words:\n",
    "    print(word, \" | \", stemmer.stem(word)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "245f8b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat  |  9837207709914848172\n",
      "eats  |  eat  |  9837207709914848172\n",
      "eat  |  eat  |  9837207709914848172\n",
      "ate  |  eat  |  9837207709914848172\n",
      "adjustable  |  adjustable  |  6033511944150694480\n",
      "rafting  |  raft  |  7154368781129989833\n",
      "ability  |  ability  |  11565809527369121409\n",
      "meeting  |  meeting  |  14798207169164081740\n",
      "better  |  well  |  4525988469032889948\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp('eating eats eat ate adjustable rafting ability meeting better')\n",
    "for token in doc:\n",
    "    print(token,' | ', token.lemma_, ' | ', token.lemma)   # lemma(without underscore) gives has of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79899480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mando  |  Mando\n",
      "talked  |  talk\n",
      "for  |  for\n",
      "3  |  3\n",
      "hours  |  hour\n",
      "although  |  although\n",
      "talking  |  talk\n",
      "is  |  be\n",
      "n't  |  not\n",
      "his  |  his\n",
      "thing  |  thing\n",
      ",  |  ,\n",
      "he  |  he\n",
      "became  |  become\n",
      "talkative  |  talkative\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Mando talked for 3 hours although talking isn't his thing, he became talkative\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, ' | ', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a9df480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names   # attribute_ruler assigns rule to the attributes and can also update it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80546480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  |  bro\n",
      ",  |  ,\n",
      "you  |  you\n",
      "wanna  |  wanna\n",
      "go  |  go\n",
      "?  |  ?\n",
      "Brah  |  Brah\n",
      ",  |  ,\n",
      "do  |  do\n",
      "n't  |  not\n",
      "say  |  say\n",
      "no  |  no\n",
      "!  |  !\n",
      "I  |  I\n",
      "am  |  be\n",
      "exhausted  |  exhaust\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, ' | ', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ccbde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bro"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adecf303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bro'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a655aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  |  Brother\n",
      ",  |  ,\n",
      "you  |  you\n",
      "wanna  |  wanna\n",
      "go  |  go\n",
      "?  |  ?\n",
      "Brah  |  Brother\n",
      ",  |  ,\n",
      "do  |  do\n",
      "n't  |  not\n",
      "say  |  say\n",
      "no  |  no\n",
      "!  |  !\n",
      "I  |  I\n",
      "am  |  be\n",
      "exhausted  |  exhaust\n"
     ]
    }
   ],
   "source": [
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "\n",
    "ar.add([[{\"TEXT\": \"Bro\"}], [{\"TEXT\":\"Brah\"}]], {\"LEMMA\": \"Brother\"})\n",
    "\n",
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, ' | ', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab8a5229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bro"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b88bac0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brother'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "417227c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  |  run\n",
      "painting  |  paint\n",
      "walking  |  walk\n",
      "dressing  |  dress\n",
      "likely  |  like\n",
      "children  |  children\n",
      "whom  |  whom\n",
      "good  |  good\n",
      "ate  |  ate\n",
      "fishing  |  fish\n"
     ]
    }
   ],
   "source": [
    "#using stemming in nltk\n",
    "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']\n",
    "\n",
    "for word in lst_words:\n",
    "    print(word, \" | \", stemmer.stem(word))\n",
    "    \n",
    "# did not convert the past form into base word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82d4d84c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  |  run\n",
      "painting  |  paint\n",
      "walking  |  walk\n",
      "dressing  |  dress\n",
      "likely  |  likely\n",
      "children  |  child\n",
      "who  |  who\n",
      "good  |  good\n",
      "ate  |  eat\n",
      "fishing  |  fishing\n"
     ]
    }
   ],
   "source": [
    "#using lemmatization in spacy\n",
    "\n",
    "doc = nlp(\"running painting walking dressing likely children who good ate fishing\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, ' | ', token.lemma_)\n",
    "    \n",
    "# converted past form too in base word but fishing remains same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e3e08e",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "#### Words that are different in stemming and lemmatization are:\n",
    "\n",
    "painting\n",
    "likely\n",
    "children\n",
    "ate\n",
    "fishing\n",
    "As Stemming achieves the base word by removing the suffixes [ing, ly etc], so it successfully transform the words like 'painting', 'likely', 'fishing' and lemmatization fails for some words ending with suffixes here.\n",
    "\n",
    "As Lemmatization uses the dictionary meanings while converting to the base form, so words like 'children' and 'ate' are successfully transformed and stemming fails here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e389dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1997e6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'latha is veri multi talent girl.sh is good at mani skill like danc , run , sing , playing.sh also like eat pav bhagi . she ha a habit of fish and swim too.besid all thi , she is a wonder at cook too .'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using stemming in nltk\n",
    "\n",
    "#step1: Word tokenizing\n",
    "all_word_tokenize = nltk.word_tokenize(text)\n",
    "\n",
    "\n",
    "#step2: getting the base form for each token using stemmer\n",
    "base_form = []\n",
    "for token in all_word_tokenize:\n",
    "    base_form.append(stemmer.stem(token))\n",
    "base_form\n",
    "\n",
    "#step3: joining all words in a list into string using 'join()'\n",
    "complete_string = ' '.join(base_form)\n",
    "complete_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7251b6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Latha be very multi talented girl . she be good at many skill like dancing , running , singing , play . she also like eat Pav Bhagi . she have a \\n habit of fishing and swim too . besides all this , she be a wonderful at cook too . \\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using lemmatisation in spacy\n",
    "\n",
    "\n",
    "#step1: Creating the object for the given text\n",
    "doc = nlp(text)\n",
    "\n",
    "\n",
    "#step2: getting the base form for each token using spacy 'lemma_'\n",
    "\n",
    "base_word = []\n",
    "for token in doc:\n",
    "    base_word.append(token.lemma_)\n",
    "\n",
    "\n",
    "#step3: joining all words in a list into string using 'join()'\n",
    "complete_sentence = ' '.join(base_word)\n",
    "complete_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2faf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
